{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# connect to Groq API (OpenAI-compatible)\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),   # get key from env var\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grf2JZCE_1Wj",
        "outputId": "7c199116-e649-4915-866d-2f8874304e4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.106.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store conversation history\n",
        "conversation_history = []\n",
        "\n",
        "def add_message(role, content):\n",
        "    \"\"\"Add a new message to the conversation history\"\"\"\n",
        "    conversation_history.append({\"role\": role, \"content\": content})\n"
      ],
      "metadata": {
        "id": "_QZCNmT0AAu6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_by_turns(history, n=5):\n",
        "    \"\"\"Keep only the last n turns of the conversation\"\"\"\n",
        "    return history[-n:]\n",
        "\n",
        "def truncate_by_words(history, max_words=50):\n",
        "    \"\"\"Keep conversation within max_words\"\"\"\n",
        "    new_history = []\n",
        "    word_count = 0\n",
        "    for msg in reversed(history):\n",
        "        words = msg[\"content\"].split()\n",
        "        if word_count + len(words) <= max_words:\n",
        "            new_history.insert(0, msg)\n",
        "            word_count += len(words)\n",
        "        else:\n",
        "            break\n",
        "    return new_history\n"
      ],
      "metadata": {
        "id": "Bh2_xQiYAFcv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_conversation(history):\n",
        "    \"\"\"Summarize conversation using Groq model\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",  # Groq model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Summarize the following conversation briefly.\"},\n",
        "            {\"role\": \"user\", \"content\": str(history)}\n",
        "        ]\n",
        "    )\n",
        "    summary = response.choices[0].message.content\n",
        "    return {\"role\": \"system\", \"content\": f\"Summary: {summary}\"}\n"
      ],
      "metadata": {
        "id": "d3RnRW2GAHHu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manage_conversation(new_user_message, k=3, run_count=[0]):\n",
        "    \"\"\"Add new message, simulate assistant reply, and summarize after k runs\"\"\"\n",
        "    add_message(\"user\", new_user_message)\n",
        "\n",
        "    # simulate assistant reply\n",
        "    reply = f\"(assistant reply to: {new_user_message})\"\n",
        "    add_message(\"assistant\", reply)\n",
        "\n",
        "    run_count[0] += 1\n",
        "\n",
        "    # summarize after every k runs\n",
        "    if run_count[0] % k == 0:\n",
        "        summary_msg = summarize_conversation(conversation_history)\n",
        "        conversation_history.clear()\n",
        "        conversation_history.append(summary_msg)\n",
        "        return summary_msg\n",
        "    else:\n",
        "        return {\"role\": \"assistant\", \"content\": reply}\n"
      ],
      "metadata": {
        "id": "d8rz5d6cAM-u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(manage_conversation(\"Hi, I want to order food\"))\n",
        "print(manage_conversation(\"Maybe Italian\"))\n",
        "print(manage_conversation(\"Pizza please\"))\n",
        "print(\"Current history:\", conversation_history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_gyIYALAPym",
        "outputId": "c31790e8-d0cd-4b3a-aff2-d4300e64db89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'assistant', 'content': '(assistant reply to: Hi, I want to order food)'}\n",
            "{'role': 'assistant', 'content': '(assistant reply to: Maybe Italian)'}\n",
            "{'role': 'system', 'content': 'Summary: The conversation involves a user trying to order food with an assistant. The user asks \"Hi, I want to order food\" and then specifies their preference for Italian food and ordering a pizza. However, instead of proceeding with the order, the conversation starts from the beginning, repeating the user\\'s same requests multiple times without any actual outcome.'}\n",
            "Current history: [{'role': 'system', 'content': 'Summary: The conversation involves a user trying to order food with an assistant. The user asks \"Hi, I want to order food\" and then specifies their preference for Italian food and ordering a pizza. However, instead of proceeding with the order, the conversation starts from the beginning, repeating the user\\'s same requests multiple times without any actual outcome.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary: A user initiated a conversation with an assistant to order food,\n",
        "specifying they might want Italian food and specifically ordering pizza.\n",
        "The conversation repeats itself from the beginning after the first cycle,\n",
        "suggesting a loop occurred or the conversation was restarted.\n"
      ],
      "metadata": {
        "id": "smryw7_MCtDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install & setup\n",
        "!pip install openai jsonschema --quiet\n",
        "\n",
        "from openai import OpenAI\n",
        "import os, json, re\n",
        "from jsonschema import validate, ValidationError, FormatChecker\n",
        "\n",
        "# Get API key safely\n",
        "input(\"Paste your Groq API key (keep it private): \").strip()\n",
        "\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),   # get key from env var\n",
        "\n",
        "# Choose a current Groq model that supports function-calling\n",
        "DEFAULT_MODEL = \"llama-3.1-8b-instant\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "OvYxr9URCuhG",
        "outputId": "9a10d527-72a4-4b34-d9cf-64a8e2fbb9ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2643084462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get API key safely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Paste your Groq API key (keep it private): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://api.groq.com/openai/v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  define the function schema used in function-calling\n",
        "extract_fn = {\n",
        "    \"name\": \"extract_user_info\",\n",
        "    \"description\": \"Extract name, email, phone, location, and age from a user chat message.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\", \"description\": \"Full name\"},\n",
        "            \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
        "            \"phone\": {\"type\": \"string\", \"description\": \"Phone number (digits or with country code)\"},\n",
        "            \"location\": {\"type\": \"string\", \"description\": \"City or place\"},\n",
        "            \"age\": {\"type\": \"integer\", \"minimum\": 0}\n",
        "        },\n",
        "        \"required\": [\"name\", \"email\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "functions = [extract_fn]\n"
      ],
      "metadata": {
        "id": "Gfv43aq9vtX7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  call the model and safely parse the function_call arguments (JSON)\n",
        "def call_extractor(chat_text, model=DEFAULT_MODEL):\n",
        "    \"\"\"\n",
        "    Sends the chat_text to the model with a function definition and forces a function call.\n",
        "    Returns (parsed_dict, full_response_object).\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a JSON extractor. Extract user contact details using the provided function signature.\"},\n",
        "        {\"role\": \"user\", \"content\": chat_text}\n",
        "    ]\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        # Force the model to return a function call\n",
        "        function_call={\"name\": \"extract_user_info\"}\n",
        "    )\n",
        "\n",
        "    # Extract the first message\n",
        "    message = resp.choices[0].message\n",
        "\n",
        "    # The function_call may be an attribute or dict depending on client object type.\n",
        "    fn_call = None\n",
        "    if isinstance(message, dict):\n",
        "        fn_call = message.get(\"function_call\")\n",
        "    else:\n",
        "        fn_call = getattr(message, \"function_call\", None)\n",
        "\n",
        "    # If function_call not present, try to parse the message content as JSON\n",
        "    if not fn_call:\n",
        "        content = message.get(\"content\") if isinstance(message, dict) else getattr(message, \"content\", \"\")\n",
        "        try:\n",
        "            parsed = json.loads(content)\n",
        "        except Exception:\n",
        "            parsed = {}\n",
        "        return parsed, resp\n",
        "\n",
        "    # Extract arguments string\n",
        "    args_str = fn_call.get(\"arguments\") if isinstance(fn_call, dict) else getattr(fn_call, \"arguments\", \"\")\n",
        "\n",
        "    # Parse arguments JSON with fallback handling\n",
        "    try:\n",
        "        parsed = json.loads(args_str)\n",
        "    except json.JSONDecodeError:\n",
        "        # Try to extract the first {...} substring and parse\n",
        "        m = re.search(r\"\\{.*\\}\", args_str, flags=re.S)\n",
        "        if m:\n",
        "            try:\n",
        "                parsed = json.loads(m.group(0))\n",
        "            except Exception:\n",
        "                parsed = {}\n",
        "        else:\n",
        "            parsed = {}\n",
        "\n",
        "    return parsed, resp\n"
      ],
      "metadata": {
        "id": "GBAFSdmlv6IU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate extracted JSON against the schema\n",
        "schema_for_validation = extract_fn[\"parameters\"]\n",
        "\n",
        "def validate_extracted(data):\n",
        "    \"\"\"\n",
        "    Validates `data` (a dict) against the JSON schema. Returns (is_valid: bool, error_message_or_None).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        validate(instance=data, schema=schema_for_validation, format_checker=FormatChecker())\n",
        "        return True, None\n",
        "    except ValidationError as e:\n",
        "        return False, str(e)\n"
      ],
      "metadata": {
        "id": "BBsqACSuwIcg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample chats and run the extractor on each\n",
        "samples = [\n",
        "    # sample 1: all fields present (clean)\n",
        "    \"Hi, I'm Priya Sharma, 28 years old, from Mumbai. My email is priya.sharma@example.com and phone is +91-9876543210.\",\n",
        "    # sample 2: missing phone (should still validate if required are present)\n",
        "    \"Hello, name is Rahul. You can reach me at rahul@example.com. I'm 35 and live in Delhi.\",\n",
        "    # sample 3: different phone format, lowercased email\n",
        "    \"Hey, I'm Anu. Contact: 9988776655. Email: anu99@mail.com. Age: 22. Location: Bengaluru\"\n",
        "]\n",
        "\n",
        "for i, s in enumerate(samples, 1):\n",
        "    extracted, resp = call_extractor(s)\n",
        "    valid, error = validate_extracted(extracted)\n",
        "    print(f\"--- Sample {i} ---\")\n",
        "    print(\"Input:\", s)\n",
        "    print(\"Extracted JSON:\")\n",
        "    print(json.dumps(extracted, indent=2))\n",
        "    print(\"Valid according to schema?:\", valid)\n",
        "    if not valid:\n",
        "        print(\"Validation error:\", error)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ufFyOq-wM_L",
        "outputId": "8b034794-f70d-4754-ac14-a8ffa515a64f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Sample 1 ---\n",
            "Input: Hi, I'm Priya Sharma, 28 years old, from Mumbai. My email is priya.sharma@example.com and phone is +91-9876543210.\n",
            "Extracted JSON:\n",
            "{\n",
            "  \"age\": 28,\n",
            "  \"email\": \"priya.sharma@example.com\",\n",
            "  \"location\": \"Mumbai\",\n",
            "  \"name\": \"Priya Sharma\",\n",
            "  \"phone\": \"+91-9876543210\"\n",
            "}\n",
            "Valid according to schema?: True\n",
            "\n",
            "--- Sample 2 ---\n",
            "Input: Hello, name is Rahul. You can reach me at rahul@example.com. I'm 35 and live in Delhi.\n",
            "Extracted JSON:\n",
            "{\n",
            "  \"age\": 35,\n",
            "  \"email\": \"rahul@example.com\",\n",
            "  \"location\": \"Delhi\",\n",
            "  \"name\": \"Rahul\",\n",
            "  \"phone\": \"\"\n",
            "}\n",
            "Valid according to schema?: True\n",
            "\n",
            "--- Sample 3 ---\n",
            "Input: Hey, I'm Anu. Contact: 9988776655. Email: anu99@mail.com. Age: 22. Location: Bengaluru\n",
            "Extracted JSON:\n",
            "{\n",
            "  \"age\": 22,\n",
            "  \"email\": \"anu99@mail.com\",\n",
            "  \"location\": \"Bengaluru\",\n",
            "  \"name\": \"Anu\",\n",
            "  \"phone\": \"9988776655\"\n",
            "}\n",
            "Valid according to schema?: True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample that misses required field (email) to demonstrate validation failure\n",
        "sample_missing_email = \"Hi, I'm Sam Kumar and I live in Pune. My phone is 9876543210.\"\n",
        "extracted, _ = call_extractor(sample_missing_email)\n",
        "valid, error = validate_extracted(extracted)\n",
        "\n",
        "print(\"Input:\", sample_missing_email)\n",
        "print(\"Extracted:\", json.dumps(extracted, indent=2))\n",
        "print(\"Valid?:\", valid)\n",
        "if not valid:\n",
        "    print(\"Validation error:\", error)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXDsocBbwRTs",
        "outputId": "0505dab0-41f8-4e7a-dc77-fb2997728e09"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hi, I'm Sam Kumar and I live in Pune. My phone is 9876543210.\n",
            "Extracted: {\n",
            "  \"age\": 30,\n",
            "  \"email\": \"sam.kumar@example.com\",\n",
            "  \"location\": \"Pune\",\n",
            "  \"name\": \"Sam Kumar\",\n",
            "  \"phone\": \"9876543210\"\n",
            "}\n",
            "Valid?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: JSON Schema Classification & Information Extraction\n",
        "\n",
        "In this task I define a JSON schema for extracting user details (`name`, `email`, `phone`, `location`, `age`) and use the Groq (OpenAI-compatible) client with function-calling to get structured outputs.\n",
        "\n",
        "**Approach**\n",
        "- Define a `functions` entry that contains a JSON schema (`parameters`) describing expected output.\n",
        "- Call the Groq model with `functions=[...]` and `function_call={\"name\":\"extract_user_info\"}` to force the model to return structured arguments.\n",
        "- Parse the returned `function_call.arguments` (JSON string) and validate it using `jsonschema.validate` against the same schema.\n",
        "- Demonstrate with 3+ sample chats and one failing example to show validation behavior.\n",
        "\n",
        "**Notes**\n",
        "- Required fields in the schema: `name` and `email`.\n",
        "- We use `jsonschema` with `FormatChecker()` to validate email format.\n",
        "- Keep API keys private. Use environment variables or a secure prompt in Colab.\n"
      ],
      "metadata": {
        "id": "YXjwzWvGx56z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ohl9ORvlyKb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}